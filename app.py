import streamlit as st
import pandas as pd
from bs4 import BeautifulSoup
import re
from streamlit_gsheets import GSheetsConnection
from datetime import datetime

# ÌéòÏù¥ÏßÄ ÏÑ§Ï†ï
st.set_page_config(page_title="ÏÇºÏ≤úÎ¶¨ ÌôçÎ≥¥ÌåÄ ÌòÑÌô©Ìåê", layout="wide")
conn = st.connection("gsheets", type=GSheetsConnection)
SHEET_NAME = "2026ÎÖÑ"

st.title("üè¢ Î≥¥ÎèÑÏûêÎ£å Í≤åÏû¨ ÌòÑÌô© ÎàÑÏ†Å Í¥ÄÎ¶¨")

# ÏûÖÎ†•Î∂Ä
col1, col2 = st.columns([1, 2])
with col1:
    doc_date = st.date_input("Î∞∞Ìè¨ ÎÇ†Ïßú", datetime.now())
    doc_title = st.text_input("Î≥¥ÎèÑÏûêÎ£å Ï†úÎ™©")
with col2:
    raw_html = st.text_area("HTML ÏÜåÏä§ Î∂ôÏó¨ÎÑ£Í∏∞", height=200)

if st.button("üöÄ ÌòÑÌô©Ìåê ÎàÑÏ†Å ÏóÖÎç∞Ïù¥Ìä∏"):
    if not doc_title or not raw_html:
        st.warning("ÎÇ¥Ïö©ÏùÑ Î™®Îëê ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
    else:
        try:
            with st.spinner("ÏóÖÎç∞Ïù¥Ìä∏ Ï§ë..."):
                # A1Î∂ÄÌÑ∞ Îç∞Ïù¥ÌÑ∞Î•º ÏàúÏàòÌïòÍ≤å ÏùΩÏñ¥Ïò¥
                df = conn.read(worksheet=SHEET_NAME, header=None).fillna("")
                
                # HTML Î∂ÑÏÑù
                soup = BeautifulSoup(raw_html, 'html.parser')
                found_media = {}
                for a_tag in soup.find_all('a', href=True):
                    url = a_tag['href']
                    span = a_tag.find_next_sibling('span')
                    if span:
                        m = re.search(r'\((.*?) \d{4}', span.get_text())
                        if m: found_media[m.group(1).strip()] = url

                # ÏÉà Ïó¥ ÏÉùÏÑ±
                new_col = [""] * len(df)
                
                # [Ï¢åÌëú Í≥†Ï†ï] 1Ìñâ: ÎÇ†Ïßú, 2Ìñâ: Ï†úÎ™©
                if len(new_col) >= 2:
                    new_col[0] = doc_date.strftime('%m/%d')
                    new_col[1] = doc_title

                # 4Ìñâ(index 3)Î∂ÄÌÑ∞ Îß§Ï≤¥Î™Ö ÎπÑÍµê
                match_count = 0
                for i in range(len(df)):
                    if i < 3: continue 
                    
                    sheet_media = str(df.iloc[i, 0]).strip()
                    if not sheet_media or sheet_media in ["0", "1"]: continue
                    
                    pure_name = re.sub(r'\(.*?\)', '', sheet_media).strip()
                    
                    found_url = None
                    for m_name, url in found_media.items():
                        if pure_name in m_name or m_name in pure_name:
                            found_url = url
                            break
                    
                    if found_url:
                        new_col[i] = f'=HYPERLINK("{found_url}", "‚úÖ")'
                        match_count += 1
                    else:
                        new_col[i] = "-"

                # Ïó¥ Ï∂îÍ∞Ä Î∞è ÏóÖÎç∞Ïù¥Ìä∏
                df[f"Col_{datetime.now().strftime('%H%M%S')}"] = new_col
                conn.update(worksheet=SHEET_NAME, data=df)
                st.success(f"‚úÖ ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å! (Îß§Ïπ≠: {match_count}Í±¥)")
                st.balloons()
        except Exception as e:
            st.error(f"Ïò§Î•ò: {e}")
