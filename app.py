import streamlit as st
import pandas as pd
from bs4 import BeautifulSoup
import re
from streamlit_gsheets import GSheetsConnection
from datetime import datetime

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì‚¼ì²œë¦¬ í™ë³´íŒ€ í˜„í™©íŒ", layout="wide")
conn = st.connection("gsheets", type=GSheetsConnection)
SHEET_NAME = "2026ë…„"

st.title("ğŸ¢ ë³´ë„ìë£Œ ê²Œì¬ í˜„í™© ëˆ„ì  ê´€ë¦¬")

# 2. ì…ë ¥ë¶€
col1, col2 = st.columns([1, 2])
with col1:
    doc_date = st.date_input("ë°°í¬ ë‚ ì§œ", datetime.now())
    doc_title = st.text_input("ë³´ë„ìë£Œ ì œëª©")
with col2:
    raw_html = st.text_area("HTML ì†ŒìŠ¤ ë¶™ì—¬ë„£ê¸°", height=200)

if st.button("ğŸš€ í˜„í™©íŒ ëˆ„ì  ì—…ë°ì´íŠ¸"):
    if not doc_title or not raw_html:
        st.warning("ì œëª©ê³¼ HTML ì†ŒìŠ¤ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        try:
            with st.spinner("ë°ì´í„° ë¶„ì„ ì¤‘..."):
                # header=Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ A1ë¶€í„° ìˆœìˆ˜ ë°ì´í„°ë¡œ ì½ì–´ì˜µë‹ˆë‹¤.
                df = conn.read(worksheet=SHEET_NAME, header=None).fillna("")
                
                # HTML ë¶„ì„
                soup = BeautifulSoup(raw_html, 'html.parser')
                found_media = {}
                for a_tag in soup.find_all('a', href=True):
                    url = a_tag['href']
                    span = a_tag.find_next_sibling('span')
                    if span:
                        m = re.search(r'\((.*?) \d{4}', span.get_text())
                        if m: found_media[m.group(1).strip()] = url

                # 3. ìƒˆë¡œìš´ ê²°ê³¼ ì—´ ìƒì„± (dfì˜ ì „ì²´ í–‰ ê°œìˆ˜ ìœ ì§€)
                new_col = [""] * len(df)
                
                # [ì¢Œí‘œ ê³ ì •] ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ì—‘ì…€ í–‰ ë²ˆí˜¸ì™€ ì •í™•íˆ ë§ì¶¤
                # 1í–‰(index 0) -> ê²°ê³¼ ID (Result_...)
                # 2í–‰(index 1) -> ë‚ ì§œ (01/23)
                # 3í–‰(index 2) -> ì œëª© (ì´íƒœí˜¸ ì‚¬ì¥...)
                if len(new_col) >= 3:
                    new_col[0] = doc_date.strftime('%m/%d') # 1í–‰ ì˜†ì— ë‚ ì§œ
                    new_col[1] = doc_title                  # 2í–‰ ì˜†ì— ì œëª©
                    # 3í–‰ë¶€í„°ëŠ” ë°ì´í„° ì˜ì—­ì…ë‹ˆë‹¤.

                match_count = 0
                # [ë§¤ì¹­ ì‹œì‘] ì—‘ì…€ 2í–‰(index 1)ì— ìˆëŠ” 'ê°€ìŠ¤ì‹ ë¬¸'ë¶€í„° ì½ìŠµë‹ˆë‹¤.
                for i in range(len(df)):
                    # 1í–‰(index 0)ì€ ìˆ«ì '1'ì´ ìˆìœ¼ë¯€ë¡œ ë§¤ì²´ëª… ë¹„êµì—ì„œ ì œì™¸
                    if i < 1: continue
                    
                    # Aì—´(index 0) ë§¤ì²´ëª… í™•ì¸
                    sheet_media = str(df.iloc[i, 0]).strip()
                    if not sheet_media or sheet_media == "1": continue
                    
                    # ë§¤ì²´ëª… ê°€ê³µ
                    pure_name = re.sub(r'\(.*?\)', '', sheet_media).strip()
                    
                    # HTML ë§¤ì¹­
                    found_url = None
                    for m_name, url in found_media.items():
                        if pure_name in m_name or m_name in pure_name:
                            found_url = url
                            break
                    
                    if found_url:
                        # âœ… ë§¤ì²´ëª…ê³¼ ë™ì¼í•œ í–‰(i)ì— ì •í™•íˆ ì²´í¬ í‘œì‹œë¥¼ í•©ë‹ˆë‹¤.
                        new_col[i] = f'=HYPERLINK("{found_url}", "âœ…")'
                        match_count += 1
                    else:
                        # ë§¤ì²´ëª…ì´ ì¡´ì¬í•˜ì§€ë§Œ ê¸°ì‚¬ê°€ ì—†ëŠ” ê²½ìš°
                        if i >= 2: # ì œëª© í–‰ ì•„ë˜ë¶€í„°ë§Œ '-' í‘œì‹œ
                            new_col[i] = "-"

                # 4. ì‹œíŠ¸ ì—…ë°ì´íŠ¸
                col_name = f"Result_{datetime.now().strftime('%H%M%S')}"
                df[col_name] = new_col
                
                conn.update(worksheet=SHEET_NAME, data=df)
                
                st.success(f"âœ… ì—…ë°ì´íŠ¸ ì„±ê³µ! (ë§¤ì¹­: {match_count}ê±´)")
                st.balloons()

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
