import streamlit as st
import pandas as pd
from bs4 import BeautifulSoup
import re
from streamlit_gsheets import GSheetsConnection
from datetime import datetime

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì‚¼ì²œë¦¬ í™ë³´íŒ€ ì„±ê³¼ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide")
conn = st.connection("gsheets", type=GSheetsConnection)
SHEET_NAME = "2026ë…„"

st.title("ğŸ“Š ë³´ë„ìë£Œ ê²Œì¬ ì„±ê³¼ ëŒ€ì‹œë³´ë“œ")

# 2. ìƒë‹¨ ì…ë ¥ë¶€
with st.container():
    col1, col2 = st.columns([1, 2])
    with col1:
        doc_date = st.date_input("ğŸ“… ë°°í¬ ë‚ ì§œ", datetime.now())
        doc_title = st.text_input("ğŸ“ ë³´ë„ìë£Œ ì œëª©", placeholder="ì˜ˆ: ì‚¼ì²œë¦¬ ì´íƒœí˜¸ ì‚¬ì¥ ì·¨ì„")
    with col2:
        raw_html = st.text_area("ğŸ”— HTML ì†ŒìŠ¤ ë¶™ì—¬ë„£ê¸°", height=150, placeholder="ìŠ¤í¬ë© HTML ì†ŒìŠ¤ë¥¼ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")

# 3. ë°ì´í„° ê¸°ë¡ ë¡œì§
if st.button("ğŸš€ ê²Œì¬ ë‚´ì—­ ì—…ë°ì´íŠ¸ ë° ë¶„ì„"):
    if not doc_title or not raw_html:
        st.warning("ì œëª©ê³¼ HTML ì†ŒìŠ¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        try:
            with st.spinner("ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì„±ì í‘œë¥¼ ê°±ì‹  ì¤‘ì…ë‹ˆë‹¤..."):
                # HTMLì—ì„œ ë§¤ì²´ëª… ì¶”ì¶œ
                soup = BeautifulSoup(raw_html, 'html.parser')
                found_media = set()
                for td in soup.find_all('td'):
                    m = re.search(r'\((.*?) \d{4}', td.get_text())
                    if m: found_media.add(m.group(1).strip())

                if not found_media:
                    st.error("HTMLì—ì„œ ë§¤ì²´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ìƒˆë¡œìš´ ë°ì´í„° ìƒì„±
                    new_entries = pd.DataFrame({
                        "ë°°í¬ì¼": [doc_date.strftime('%Y-%m-%d')] * len(found_media),
                        "ë³´ë„ìë£Œ ì œëª©": [doc_title] * len(found_media),
                        "ë§¤ì²´ëª…": list(found_media)
                    })

                    # ê¸°ì¡´ ë°ì´í„° ì½ê¸°
                    try:
                        existing_df = conn.read(worksheet=SHEET_NAME).fillna("")
                    except:
                        existing_df = pd.DataFrame(columns=["ë°°í¬ì¼", "ë³´ë„ìë£Œ ì œëª©", "ë§¤ì²´ëª…"])

                    # ë°ì´í„° í•©ì¹˜ê¸° (ì¤‘ë³µ ë°©ì§€ ë¡œì§ í¬í•¨ - ë™ì¼ ë‚ ì§œ/ì œëª©/ë§¤ì²´ëŠ” ì œì™¸)
                    updated_df = pd.concat([existing_df, new_entries]).drop_duplicates().reset_index(drop=True)
                    
                    # ì‹œíŠ¸ ì—…ë°ì´íŠ¸
                    conn.update(worksheet=SHEET_NAME, data=updated_df)
                    st.success(f"âœ… {len(found_media)}ê°œ ë§¤ì²´ì˜ ê²Œì¬ ë‚´ì—­ì´ ì•ˆì „í•˜ê²Œ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

st.divider()

# 4. ì‹¤ì‹œê°„ ì„±ì í‘œ(Dashboard) ì˜ì—­
st.subheader("ğŸ“ˆ 2026ë…„ ë§¤ì²´ë³„ ê²Œì¬ ì„±ì í‘œ (ì‹¤ì‹œê°„)")

try:
    # ì „ì²´ ë°ì´í„° ë‹¤ì‹œ ì½ê¸°
    df = conn.read(worksheet=SHEET_NAME).fillna("")
    
    if not df.empty:
        # ë¶„ì„ 1: ì´ ë°°í¬ ê±´ìˆ˜ (ê³ ìœ í•œ ì œëª©ì˜ ê°œìˆ˜)
        total_pr_count = df["ë³´ë„ìë£Œ ì œëª©"].nunique()
        
        # ë¶„ì„ 2: ë§¤ì²´ë³„ ê²Œì¬ íšŸìˆ˜ ê³„ì‚°
        scorecard = df.groupby("ë§¤ì²´ëª…").size().reset_index(name="ê²Œì¬ íšŸìˆ˜")
        scorecard["ê²Œì¬ìœ¨ (%)"] = scorecard["ê²Œì¬ íšŸìˆ˜"].apply(lambda x: f"{(x / total_pr_count * 100):.1f}%")
        scorecard = scorecard.sort_values(by="ê²Œì¬ íšŸìˆ˜", ascending=False).reset_index(drop=True)

        # í™”ë©´ í‘œì‹œ
        c1, c2 = st.columns([1, 3])
        with c1:
            st.metric("ì˜¬í•´ ì´ ë°°í¬ ê±´ìˆ˜", f"{total_pr_count}ê±´")
        with c2:
            st.dataframe(scorecard, use_container_width=True)
            
        st.caption("â€» ê²Œì¬ìœ¨ = (í•´ë‹¹ ë§¤ì²´ ê²Œì¬ íšŸìˆ˜ / ì „ì²´ ë³´ë„ìë£Œ ë°°í¬ ê±´ìˆ˜) * 100")
    else:
        st.info("ê¸°ë¡ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë³´ë„ìë£Œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
except:
    st.info("ì‹œíŠ¸ë¥¼ ì½ì–´ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
