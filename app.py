import streamlit as st
import pandas as pd
from bs4 import BeautifulSoup
import re
from streamlit_gsheets import GSheetsConnection
from datetime import datetime

# ... (ìƒë‹¨ ì„¤ì • ë™ì¼)

if st.button("ğŸš€ í˜„í™©íŒ ì—…ë°ì´íŠ¸"):
    if not doc_title or not raw_html:
        st.warning("ì œëª©ê³¼ HTML ì†ŒìŠ¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        try:
            # 1. ì‹œíŠ¸ ì½ê¸°
            df = conn.read(worksheet=SHEET_NAME, header=None).fillna("")
            
            # 2. HTML ë¶„ì„ (ì£¼ì‹  ì†ŒìŠ¤ ì „ìš© ë¡œì§)
            soup = BeautifulSoup(raw_html, 'html.parser')
            media_map = {} # { "ë§¤ì²´ëª…": "URL" }
            
            # ëª¨ë“  <a> íƒœê·¸ë¥¼ ì°¾ì•„ì„œ ë¶„ì„
            for a_tag in soup.find_all('a', href=True):
                url = a_tag['href']
                # <a> íƒœê·¸ ë°”ë¡œ ë’¤ì— ìˆëŠ” <span> íƒœê·¸ì—ì„œ ë§¤ì²´ëª… ì¶”ì¶œ
                span = a_tag.find_next_sibling('span')
                if span:
                    span_text = span.get_text()
                    # (ë§¤ì²´ëª… 2026/01/23) íŒ¨í„´ì—ì„œ ë§¤ì²´ëª…ë§Œ ì¶”ì¶œ
                    m = re.search(r'\((.*?) \d{4}', span_text)
                    if m:
                        media_name = m.group(1).strip()
                        media_map[media_name] = url

            if not media_map:
                st.warning("ë§¤ì²´ëª…ê³¼ URLì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. HTML í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                st.stop()

            # 3. ìƒˆë¡œìš´ ì—´ ë°ì´í„° ìƒì„±
            new_col = [""] * len(df)
            if len(new_col) > 2:
                new_col[1] = doc_date.strftime('%m/%d')
                new_col[2] = doc_title

            # 4. ì‹œíŠ¸ì˜ Bì—´(ë§¤ì²´ëª…)ê³¼ ë§¤ì¹­
            match_count = 0
            for i in range(len(df)):
                if i < 3 or df.shape[1] < 2: continue
                
                # ì‹œíŠ¸ ìƒì˜ ë§¤ì²´ëª… (ì˜ˆ: ì¡°ì„ ì¼ë³´)
                sheet_media_name = str(df.iloc[i, 1]).strip()
                # ê´„í˜¸ ë“± ì œê±°í•˜ê³  ìˆœìˆ˜ ì´ë¦„ë§Œ ì¶”ì¶œ
                pure_name = re.sub(r'\(.*?\)', '', sheet_media_name).strip()
                
                # ì¶”ì¶œëœ media_mapì—ì„œ ìœ ì‚¬í•œ ì´ë¦„ ì°¾ê¸°
                found_url = None
                for m_name, url in media_map.items():
                    if pure_name in m_name or m_name in pure_name:
                        found_url = url
                        break
                
                if found_url:
                    # ì‹œíŠ¸ì— í•˜ì´í¼ë§í¬ë¡œ ì…ë ¥
                    new_col[i] = f'=HYPERLINK("{found_url}", "ë³´ê¸°(âœ…)")'
                    match_count += 1
                else:
                    new_col[i] = "-"

            # 5. ì—´ ì¶”ê°€ ë° ì—…ë°ì´íŠ¸
            # ì»¬ëŸ¼ëª… ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ë‚ ì§œ_ì‹œê°„ í™œìš©
            col_id = datetime.now().strftime('%m%d_%H%M%S')
            df[f"ê²°ê³¼_{col_id}"] = new_col
            
            conn.update(worksheet=SHEET_NAME, data=df)
            
            st.success(f"âœ… ì—…ë°ì´íŠ¸ ì„±ê³µ! (ë§¤ì¹­ëœ ê¸°ì‚¬: {match_count}ê±´)")
            st.info(f"ì¶”ì¶œëœ ë§¤ì²´: {', '.join(media_map.keys())}")
            st.balloons()
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
