import streamlit as st
import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="í™ë³´íŒ€ ê¸°ì‚¬ ë§¤ì¹­ ë¶„ì„ íˆ´", layout="wide")

st.title("ğŸ“° ë³´ë„ìë£Œ ì»¤ë²„ë¦¬ì§€ ìë™ ë¶„ì„ê¸°")
st.write("ëª¨ë‹ˆí„°ë§ ë©”ì¼ì˜ ì†ŒìŠ¤ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ìœ¼ì‹œë©´ ì–¸ë¡ ì‚¬ë³„ ë§¤ì¹­ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.")

# ì¢Œìš° í™”ë©´ ë¶„í• 
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("1. ì›ë³¸ ë³´ë„ìë£Œ")
    origin_text = st.text_area("ë°°í¬í•œ ë³´ë„ìë£Œ ë³¸ë¬¸ì„ ë„£ì–´ì£¼ì„¸ìš”.", height=400)
    threshold = st.slider("ë§¤ì¹­ ì¸ì • ê¸°ì¤€ (%)", 0, 100, 60)

with col2:
    st.subheader("2. ëª¨ë‹ˆí„°ë§ HTML ì†ŒìŠ¤")
    raw_html = st.text_area("ë©”ì¼ ì†ŒìŠ¤(HTML)ë¥¼ í†µì§¸ë¡œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.", height=400, placeholder="<tr>...<a href=...>...</tr>...")

if st.button("ğŸš€ ë¶„ì„ ì‹œì‘"):
    if not origin_text:
        st.warning("ë³´ë„ìë£Œ ì›ë³¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not raw_html:
        st.warning("ë¶„ì„í•  ì†ŒìŠ¤ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # HTML íŒŒì‹± ì‹œì‘
        soup = BeautifulSoup(raw_html, 'html.parser')
        rows = soup.find_all('td', style=lambda x: x and 'padding-left:20px' in x)
        
        # ê¸°ì‚¬ ì •ë³´ ì¶”ì¶œ
        extracted_data = []
        for row in rows:
            link_tag = row.find('a', href=True)
            if link_tag:
                url = link_tag['href']
                title = link_tag.get_text(strip=True)
                
                # ë§¤ì²´ëª… ì¶”ì¶œ (ê´„í˜¸ ì•ˆì˜ í…ìŠ¤íŠ¸ ì°¾ê¸°: ì˜ˆ - ê°€ìŠ¤ì‹ ë¬¸)
                media_info = row.find('span')
                media_name = "ì•Œ ìˆ˜ ì—†ìŒ"
                if media_info:
                    media_text = media_info.get_text(strip=True)
                    match = re.search(r'\((.*?) \d{4}', media_text) # (ë§¤ì²´ëª… ë‚ ì§œ) í˜•ì‹ ì¶”ì¶œ
                    if match:
                        media_name = match.group(1)
                    else:
                        media_name = media_text.replace('(','').split(' ')[0]

                extracted_data.append({
                    "media": media_name,
                    "title": title,
                    "url": url
                })

        if not extracted_data:
            st.error("ì…ë ¥í•œ ì†ŒìŠ¤ì—ì„œ ê¸°ì‚¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, data in enumerate(extracted_data):
                status_text.text(f"ë¶„ì„ ì¤‘ ({i+1}/{len(extracted_data)}): {data['media']} - {data['title'][:20]}...")
                
                try:
                    # 1. ê¸°ì‚¬ ë³¸ë¬¸ ìˆ˜ì§‘
                    res = requests.get(data['url'], headers={'User-Agent':'Mozilla/5.0'}, timeout=5)
                    res.encoding = res.apparent_encoding # í•œê¸€ ê¹¨ì§ ë°©ì§€
                    article_soup = BeautifulSoup(res.text, 'html.parser')
                    
                    # ë‰´ìŠ¤ ë³¸ë¬¸ì´ ì£¼ë¡œ ìœ„ì¹˜í•˜ëŠ” íƒœê·¸ë“¤ ì¶”ì¶œ
                    content_tag = article_soup.find('article') or article_soup.find('div', id='dic_area') or article_soup.find('div', id='articleBody') or article_soup.body
                    content_text = content_tag.get_text(strip=True) if content_tag else ""
                    
                    # 2. ìœ ì‚¬ë„ ê³„ì‚°
                    if len(content_text) > 50: # ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì œì™¸
                        docs = [origin_text, content_text]
                        vec = TfidfVectorizer().fit_transform(docs)
                        sim = cosine_similarity(vec[0:1], vec[1:]).flatten()[0]
                        score = round(sim * 100, 1)
                        result_status = "âœ… ë§¤ì¹­" if score >= threshold else "â“ ì¼ë°˜"
                    else:
                        score = 0
                        result_status = "âš ï¸ ë³¸ë¬¸ë¶€ì¡±"
                except:
                    score = 0
                    result_status = "âŒ ì˜¤ë¥˜"
                
                results.append({
                    "ë§¤ì²´ëª…": data['media'],
                    "ê¸°ì‚¬ ì œëª©": data['title'],
                    "ì¼ì¹˜ìœ¨(%)": score,
                    "íŒë³„": result_status,
                    "ë§í¬": data['url']
                })
                progress_bar.progress((i + 1) / len(extracted_data))
            
            status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
            
            # ê²°ê³¼ í…Œì´ë¸”
            df = pd.DataFrame(results)
            st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
            st.dataframe(df, use_container_width=True)
            
            # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ê²°ê³¼ ì—‘ì…€ë¡œ ì €ì¥", csv, "pr_report.csv", "text/csv")
