import streamlit as st
import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="í™ë³´íŒ€ ê¸°ì‚¬ ë§¤ì¹­ íˆ´", layout="wide")

st.title("ğŸ“‚ ë³´ë„ìë£Œ ì»¤ë²„ë¦¬ì§€ ìë™ ì²´í¬")
st.write("ëª¨ë‹ˆí„°ë§ ì—…ì²´ì—ì„œ ì˜¨ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë“œë˜ê·¸í•´ì„œ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”!")

# ì¢Œìš° í™”ë©´ ë¶„í• 
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("1. ë°°í¬í•œ ë³´ë„ìë£Œ")
    origin_text = st.text_area("ë³´ë„ìë£Œ ë³¸ë¬¸ì„ ë„£ì–´ì£¼ì„¸ìš”.", height=400)
    threshold = st.slider("ìœ ì‚¬ë„ ê¸°ì¤€ (%)", 0, 100, 60, help="ë³´í†µ 60% ì´ìƒì´ë©´ ë³´ë„ìë£Œ ê¸°ë°˜ ê¸°ì‚¬ì…ë‹ˆë‹¤.")

with col2:
    st.subheader("2. ëª¨ë‹ˆí„°ë§ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸")
    raw_input = st.text_area("ê¸°ì‚¬ ì œëª©ê³¼ URLì´ ì„ì¸ í…ìŠ¤íŠ¸ë¥¼ í†µì§¸ë¡œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.", height=400)

if st.button("âœ¨ ë¶„ì„ ì‹œì‘ (ê¸°ì‚¬ ì½ì–´ì˜¤ê¸°)"):
    # í…ìŠ¤íŠ¸ì—ì„œ URLë§Œ ë½‘ì•„ë‚´ê¸°
    urls = re.findall(r'(https?://[^\s\n]+)', raw_input)
    
    if not origin_text:
        st.warning("ì›ë³¸ ë³´ë„ìë£Œë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not urls:
        st.warning("ë¶„ì„í•  ê¸°ì‚¬ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        results = []
        bar = st.progress(0)
        
        for idx, url in enumerate(urls):
            try:
                # ê¸°ì‚¬ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸° (ê°„ë‹¨ ë²„ì „)
                res = requests.get(url, headers={'User-Agent':'Mozilla/5.0'}, timeout=5)
                soup = BeautifulSoup(res.text, 'html.parser')
                # ë³´í†µ ì–¸ë¡ ì‚¬ ë³¸ë¬¸ì€ articleì´ë‚˜ íŠ¹ì • id ì•ˆì— ìˆìŠµë‹ˆë‹¤.
                content = soup.find('article') or soup.find('div', id='dic_area') or soup.body
                text = content.get_text(strip=True) if content else ""
                
                if text:
                    # ìœ ì‚¬ë„ ê³„ì‚°
                    docs = [origin_text, text]
                    vec = TfidfVectorizer().fit_transform(docs)
                    sim = cosine_similarity(vec[0:1], vec[1:]).flatten()[0]
                    score = round(sim * 100, 1)
                    
                    results.append({
                        "ê¸°ì‚¬ URL": url,
                        "ì¼ì¹˜ìœ¨(%)": score,
                        "íŒë³„": "âœ… ë§¤ì¹­" if score >= threshold else "â“ ì¼ë°˜/íƒ€ì‚¬"
                    })
                else:
                    results.append({"ê¸°ì‚¬ URL": url, "ì¼ì¹˜ìœ¨(%)": 0, "íŒë³„": "ì ‘ì† ë¶ˆê°€"})
            except:
                results.append({"ê¸°ì‚¬ URL": url, "ì¼ì¹˜ìœ¨(%)": 0, "íŒì…": "ì˜¤ë¥˜"})
            
            bar.progress((idx + 1) / len(urls))

        # ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
        df = pd.DataFrame(results)
        st.subheader("ğŸ“ ë¶„ì„ ë¦¬í¬íŠ¸")
        st.dataframe(df, use_container_width=True)
        
        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ê²°ê³¼ë¥¼ ì—‘ì…€ë¡œ ì €ì¥í•˜ê¸°", csv, "report.csv", "text/csv")
